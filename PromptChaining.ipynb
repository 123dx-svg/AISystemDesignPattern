{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883e5156",
   "metadata": {},
   "source": [
    "# Prompt Chaining 模式演示\n",
    "\n",
    "本notebook演示了Prompt Chaining（提示链）模式，这是一种将多个LLM调用串联起来的技术。\n",
    "每个模型的输出作为下一个模型的输入，形成一个处理链条。\n",
    "\n",
    "**工作流程：**\n",
    "1. LLM-1 (gpt-5-mini) 生成初始内容\n",
    "2. 过滤函数处理LLM-1的输出\n",
    "3. LLM-2 (claude-sonnet-4-5) 接收过滤后的内容并进行处理\n",
    "4. LLM-3 (deepseek) 接收LLM-2的输出并生成最终结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a86555",
   "metadata": {},
   "source": [
    "## 1、加载密钥环境OpenRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbf84bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API Key loaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load API Key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36a266",
   "metadata": {},
   "source": [
    "## 2、初始化OpenRouter客户端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e75d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "openrouter = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=api_key)\n",
    "print(\"OpenRouter客户端初始化成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b60f8e",
   "metadata": {},
   "source": [
    "## 3、定义过滤函数\n",
    "\n",
    "这个函数用于处理第一个LLM的输出，提取关键信息并格式化，为第二个LLM做准备。\n",
    "在实际应用中，这个函数可以执行各种处理：\n",
    "- 提取关键信息\n",
    "- 格式化输出\n",
    "- 数据清洗\n",
    "- 结构化转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35016948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_process(text):\n",
    "    \"\"\"\n",
    "    过滤和处理LLM-1的输出\n",
    "    \n",
    "    参数:\n",
    "        text: 第一个LLM的原始输出\n",
    "    \n",
    "    返回:\n",
    "        处理后的文本，用于传递给下一个LLM\n",
    "    \"\"\"\n",
    "    # 移除多余的空行\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    \n",
    "    # 提取关键句子（这里简单地按句号分割并过滤短句）\n",
    "    sentences = [s.strip() for s in text.split('。') if len(s.strip()) > 10]\n",
    "    \n",
    "    # 统计信息\n",
    "    word_count = len(text)\n",
    "    sentence_count = len(sentences)\n",
    "    \n",
    "    # 构建过滤后的输出\n",
    "    filtered_output = {\n",
    "        \"original_length\": word_count,\n",
    "        \"sentence_count\": sentence_count,\n",
    "        \"key_sentences\": sentences[:5],  # 只保留前5个关键句子\n",
    "        \"summary\": text[:200] + \"...\" if len(text) > 200 else text  # 摘要\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== 过滤函数处理结果 ===\")\n",
    "    print(f\"原始文本长度: {word_count} 字符\")\n",
    "    print(f\"提取句子数量: {sentence_count} 句\")\n",
    "    print(f\"保留关键句子: {len(filtered_output['key_sentences'])} 句\")\n",
    "    \n",
    "    return filtered_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e85f75",
   "metadata": {},
   "source": [
    "## 4、第一步：LLM-1 生成初始内容\n",
    "\n",
    "使用 **gpt-5-mini** 模型生成关于某个主题的初始内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb259e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义初始提示\n",
    "initial_prompt = \"请写一篇关于人工智能在医疗领域应用的简短文章，包括当前的应用场景、面临的挑战和未来的发展方向。\"\n",
    "\n",
    "print(\"=== 第一步：LLM-1 (gpt-5-mini) 生成初始内容 ===\")\n",
    "print(f\"输入提示: {initial_prompt}\\n\")\n",
    "\n",
    "# 调用第一个模型\n",
    "model_1 = \"gpt-5-mini\"\n",
    "messages_1 = [{\"role\": \"user\", \"content\": initial_prompt}]\n",
    "\n",
    "response_1 = openrouter.chat.completions.create(\n",
    "    model=model_1,\n",
    "    messages=messages_1\n",
    ")\n",
    "\n",
    "output_1 = response_1.choices[0].message.content\n",
    "print(f\"\\n模型: {model_1}\")\n",
    "print(\"=\"*50)\n",
    "display(Markdown(output_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d6f7f",
   "metadata": {},
   "source": [
    "## 5、第二步：过滤和处理LLM-1的输出\n",
    "\n",
    "使用自定义过滤函数处理第一个模型的输出，提取关键信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== 第二步：过滤处理 ===\")\n",
    "filtered_data = filter_and_process(output_1)\n",
    "\n",
    "print(\"\\n过滤后的数据结构:\")\n",
    "print(json.dumps(filtered_data, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e925e",
   "metadata": {},
   "source": [
    "## 6、第三步：LLM-2 处理过滤后的内容\n",
    "\n",
    "使用 **anthropic/claude-sonnet-4-5** 模型对过滤后的内容进行深度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== 第三步：LLM-2 (claude-sonnet-4-5) 深度分析 ===\")\n",
    "\n",
    "# 构建第二个模型的提示\n",
    "prompt_2 = f\"\"\"基于以下关于AI医疗应用的内容摘要和关键句子，请进行深度分析：\n",
    "\n",
    "内容摘要：\n",
    "{filtered_data['summary']}\n",
    "\n",
    "关键句子：\n",
    "{chr(10).join([f\"{i+1}. {s}\" for i, s in enumerate(filtered_data['key_sentences'])])}\n",
    "\n",
    "请从以下角度进行分析：\n",
    "1. 技术可行性评估\n",
    "2. 潜在的伦理问题\n",
    "3. 实施建议\n",
    "\n",
    "请提供结构化的分析报告。\"\"\"\n",
    "\n",
    "print(f\"输入提示长度: {len(prompt_2)} 字符\\n\")\n",
    "\n",
    "model_2 = \"anthropic/claude-sonnet-4-5\"\n",
    "messages_2 = [{\"role\": \"user\", \"content\": prompt_2}]\n",
    "\n",
    "response_2 = openrouter.chat.completions.create(\n",
    "    model=model_2,\n",
    "    messages=messages_2\n",
    ")\n",
    "\n",
    "output_2 = response_2.choices[0].message.content\n",
    "print(f\"\\n模型: {model_2}\")\n",
    "print(\"=\"*50)\n",
    "display(Markdown(output_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0b57a",
   "metadata": {},
   "source": [
    "## 7、第四步：LLM-3 生成最终输出\n",
    "\n",
    "使用 **deepseek/deepseek-chat** 模型基于LLM-2的分析生成最终的行动计划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== 第四步：LLM-3 (deepseek) 生成最终行动计划 ===\")\n",
    "\n",
    "# 构建第三个模型的提示\n",
    "prompt_3 = f\"\"\"基于以下关于AI医疗应用的深度分析报告：\n",
    "\n",
    "{output_2}\n",
    "\n",
    "请制定一份具体的、可执行的行动计划，包括：\n",
    "1. 短期目标（6个月内）\n",
    "2. 中期目标（1-2年）\n",
    "3. 长期愿景（3-5年）\n",
    "4. 关键里程碑\n",
    "5. 资源需求\n",
    "6. 风险缓解措施\n",
    "\n",
    "请以清晰、专业的格式呈现这份行动计划。\"\"\"\n",
    "\n",
    "print(f\"输入提示长度: {len(prompt_3)} 字符\\n\")\n",
    "\n",
    "model_3 = \"deepseek/deepseek-chat\"\n",
    "messages_3 = [{\"role\": \"user\", \"content\": prompt_3}]\n",
    "\n",
    "response_3 = openrouter.chat.completions.create(\n",
    "    model=model_3,\n",
    "    messages=messages_3\n",
    ")\n",
    "\n",
    "output_3 = response_3.choices[0].message.content\n",
    "print(f\"\\n模型: {model_3}\")\n",
    "print(\"=\"*50)\n",
    "display(Markdown(output_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d9321",
   "metadata": {},
   "source": [
    "## 8、总结：Prompt Chaining 流程回顾\n",
    "\n",
    "展示整个链式调用的流程和每个阶段的输出摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Prompt Chaining 流程总结\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "### 链式调用流程：\n",
    "\n",
    "**阶段1 - 内容生成 (gpt-5-mini)**\n",
    "- 输入: 原始提示词\n",
    "- 输出长度: {len(output_1)} 字符\n",
    "- 任务: 生成AI医疗应用的初始文章\n",
    "\n",
    "**阶段2 - 数据过滤**\n",
    "- 输入: LLM-1的完整输出\n",
    "- 处理: 提取关键句子、生成摘要\n",
    "- 输出: 结构化的过滤数据\n",
    "\n",
    "**阶段3 - 深度分析 (claude-sonnet-4-5)**\n",
    "- 输入: 过滤后的关键信息\n",
    "- 输出长度: {len(output_2)} 字符\n",
    "- 任务: 从技术、伦理、实施角度进行分析\n",
    "\n",
    "**阶段4 - 行动计划 (deepseek)**\n",
    "- 输入: LLM-2的分析报告\n",
    "- 输出长度: {len(output_3)} 字符\n",
    "- 任务: 制定具体可执行的行动计划\n",
    "\n",
    "### Prompt Chaining 的优势：\n",
    "\n",
    "1. **任务分解**: 将复杂任务分解为多个简单步骤\n",
    "2. **专业化**: 每个模型专注于特定任务\n",
    "3. **质量控制**: 中间过滤步骤确保数据质量\n",
    "4. **灵活性**: 可以根据需要调整链条中的任何环节\n",
    "5. **可追溯**: 每个阶段的输出都可以被检查和验证\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7c4f2",
   "metadata": {},
   "source": [
    "## 9、可视化链式调用流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_diagram = \"\"\"\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Prompt Chaining 流程图                    │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "    ┌──────────────────┐\n",
    "    │   用户输入提示    │\n",
    "    └────────┬─────────┘\n",
    "             │\n",
    "             ▼\n",
    "    ┌──────────────────┐\n",
    "    │   LLM-1 (GPT)    │  ◄── 生成初始内容\n",
    "    │   gpt-5-mini     │\n",
    "    └────────┬─────────┘\n",
    "             │\n",
    "             ▼\n",
    "    ┌──────────────────┐\n",
    "    │   过滤函数        │  ◄── 提取关键信息\n",
    "    │  filter_process  │      格式化数据\n",
    "    └────────┬─────────┘\n",
    "             │\n",
    "             ▼\n",
    "    ┌──────────────────┐\n",
    "    │  LLM-2 (Claude)  │  ◄── 深度分析\n",
    "    │ claude-sonnet-4-5│\n",
    "    └────────┬─────────┘\n",
    "             │\n",
    "             ▼\n",
    "    ┌──────────────────┐\n",
    "    │ LLM-3 (DeepSeek) │  ◄── 生成行动计划\n",
    "    │  deepseek-chat   │\n",
    "    └────────┬─────────┘\n",
    "             │\n",
    "             ▼\n",
    "    ┌──────────────────┐\n",
    "    │   最终输出结果    │\n",
    "    └──────────────────┘\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(flow_diagram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad1884",
   "metadata": {},
   "source": [
    "## 10、保存完整的链式调用结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5324c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有结果保存到一个字典中\n",
    "chain_results = {\n",
    "    \"stage_1\": {\n",
    "        \"model\": model_1,\n",
    "        \"input\": initial_prompt,\n",
    "        \"output\": output_1,\n",
    "        \"output_length\": len(output_1)\n",
    "    },\n",
    "    \"stage_2\": {\n",
    "        \"process\": \"filter_and_process\",\n",
    "        \"filtered_data\": filtered_data\n",
    "    },\n",
    "    \"stage_3\": {\n",
    "        \"model\": model_2,\n",
    "        \"output\": output_2,\n",
    "        \"output_length\": len(output_2)\n",
    "    },\n",
    "    \"stage_4\": {\n",
    "        \"model\": model_3,\n",
    "        \"output\": output_3,\n",
    "        \"output_length\": len(output_3)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 保存到JSON文件\n",
    "with open('prompt_chaining_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(chain_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✓ 链式调用结果已保存到 prompt_chaining_results.json\")\n",
    "print(f\"\\n总共执行了 3 个LLM调用 + 1 个过滤处理\")\n",
    "print(f\"总输出字符数: {len(output_1) + len(output_2) + len(output_3)} 字符\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AINew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
